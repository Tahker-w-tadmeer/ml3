{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.156150Z",
     "start_time": "2023-12-22T00:41:25.983051Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tahkeer_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BaggingClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth  \n",
    "        self.models = [DecisionTreeClassifier(max_depth=self.max_depth) for _ in range(n_estimators)] \n",
    "        \n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        for model in self.models:\n",
    "            indices = np.random.choice(len(x), len(x), replace=True)\n",
    "            x_subset, y_subset = x.iloc[indices], y.iloc[indices] \n",
    "            model.fit(x_subset, y_subset)\n",
    "        \n",
    "        return self\n",
    "            \n",
    "\n",
    "    def predict(self, x, threshold=0.5):\n",
    "        pred = np.zeros((len(x), self.n_estimators))\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred[:, i] = model.predict(x)\n",
    "        avg_predictions = np.mean(pred, axis=1)\n",
    "        binary_predictions = (avg_predictions >= threshold).astype(int)\n",
    "        return binary_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.156883Z",
     "start_time": "2023-12-22T00:41:26.146628Z"
    }
   },
   "id": "9fac969431223e6e"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "columns.remove(\"smoking\")\n",
    "features_x = df[columns]\n",
    "class_y = df[\"smoking\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.168895Z",
     "start_time": "2023-12-22T00:41:26.155948Z"
    }
   },
   "id": "fe9ab1e20fe86d44"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features_x, class_y, test_size=0.30, shuffle=False, train_size=0.70)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.184691Z",
     "start_time": "2023-12-22T00:41:26.165788Z"
    }
   },
   "id": "cd37abfe3e698ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, max_depth=4):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            model.fit(x, y, sample_weight=weights)\n",
    "            y_pred = model.predict(x)\n",
    "            weighted_error = np.sum(weights[y_pred != y])\n",
    "            if weighted_error >= 0.5:\n",
    "                break\n",
    "\n",
    "            alpha = 0.5 * np.log((1.0 - weighted_error) / max(weighted_error, 1e-10))\n",
    "            self.alphas.append(alpha)\n",
    "            self.models.append(model)\n",
    "\n",
    "            # Update weights\n",
    "            weights *= np.exp(-alpha * y * y_pred)\n",
    "            weights /= np.sum(weights)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros(len(x))\n",
    "        for alpha, model in zip(self.alphas, self.models):\n",
    "            pred += alpha * model.predict(x)\n",
    "        return np.sign(pred)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:43:02.469353Z",
     "start_time": "2023-12-22T00:43:02.466156Z"
    }
   },
   "id": "54300543aa3d236d"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Randomly select a subset of features\n",
    "            selected_features = np.random.choice(n_features, size=int(np.sqrt(n_features)), replace=False)\n",
    "            x_subset = x[:, selected_features]\n",
    "\n",
    "            # Create a decision tree with random features\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf\n",
    "            )\n",
    "            tree.fit(x_subset, y)\n",
    "            self.models.append((tree, selected_features))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros((x.shape[0], self.n_estimators))\n",
    "        for i, (tree, selected_features) in enumerate(self.models):\n",
    "            x_subset = x[:, selected_features]\n",
    "            pred[:, i] = tree.predict(x_subset)\n",
    "\n",
    "        # Use majority voting for the final prediction\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=pred)\n",
    "        return final_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T01:06:26.186165Z",
     "start_time": "2023-12-22T01:06:26.178330Z"
    }
   },
   "id": "f4260778e822584a"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7312059431851758\n"
     ]
    }
   ],
   "source": [
    "bagging_model = BaggingClassifier(n_estimators=100, max_depth=60)\n",
    "bagging_model.fit(xtrain, ytrain)\n",
    "\n",
    "bagging_predictions = bagging_model.predict(xtest)\n",
    "bagging_accuracy = accuracy_score(ytest, bagging_predictions)\n",
    "print(f\"Bagging Accuracy: {bagging_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:43:02.462067Z",
     "start_time": "2023-12-22T00:41:26.204446Z"
    }
   },
   "id": "789d1cdb28b22062"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7195770545776877\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(n_estimators=300)\n",
    "adaboost.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = adaboost.predict(xtest)\n",
    "\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Boosting Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:44:17.100901Z",
     "start_time": "2023-12-22T00:43:02.469141Z"
    }
   },
   "id": "d0b842f92c466fda"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7144696298172302\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=150, max_depth=3, min_samples_split=2, min_samples_leaf=1)\n",
    "random_forest.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = random_forest.predict(xtest)\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Random Forest Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T01:03:43.872359Z",
     "start_time": "2023-12-22T01:03:32.833333Z"
    }
   },
   "id": "571c8202d45bc0c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "We will use grid search and randomized search methods to choose better hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53df2cafbadf3fd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Random Forest model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa36548501f9040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 3, 4, 6, 8],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Grid search: \")\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(xtest, ytest)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Test Set Score:\", test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-22T01:06:31.471428Z"
    }
   },
   "id": "9cf4faa9cf9d9238"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=params, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Random Search: \")\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(xtest, ytest)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Test Set Score:\", test_score)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c270c671b54462"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
