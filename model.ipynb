{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.156150Z",
     "start_time": "2023-12-22T00:41:25.983051Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tahkeer_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BaggingClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth  \n",
    "        self.models = [DecisionTreeClassifier(max_depth=self.max_depth) for _ in range(n_estimators)] \n",
    "        \n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        for model in self.models:\n",
    "            indices = np.random.choice(len(x), len(x), replace=True)\n",
    "            x_subset, y_subset = x.iloc[indices], y.iloc[indices] \n",
    "            model.fit(x_subset, y_subset)\n",
    "        \n",
    "        return self\n",
    "            \n",
    "\n",
    "    def predict(self, x, threshold=0.5):\n",
    "        pred = np.zeros((len(x), self.n_estimators))\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred[:, i] = model.predict(x)\n",
    "        avg_predictions = np.mean(pred, axis=1)\n",
    "        binary_predictions = (avg_predictions >= threshold).astype(int)\n",
    "        return binary_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.156883Z",
     "start_time": "2023-12-22T00:41:26.146628Z"
    }
   },
   "id": "9fac969431223e6e"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "columns.remove(\"smoking\")\n",
    "features_x = df[columns]\n",
    "class_y = df[\"smoking\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.168895Z",
     "start_time": "2023-12-22T00:41:26.155948Z"
    }
   },
   "id": "fe9ab1e20fe86d44"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features_x, class_y, test_size=0.30, shuffle=False, train_size=0.70)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:41:26.184691Z",
     "start_time": "2023-12-22T00:41:26.165788Z"
    }
   },
   "id": "cd37abfe3e698ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, max_depth=4):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            model.fit(x, y, sample_weight=weights)\n",
    "            y_pred = model.predict(x)\n",
    "            weighted_error = np.sum(weights[y_pred != y])\n",
    "            if weighted_error >= 0.5:\n",
    "                break\n",
    "\n",
    "            alpha = 0.5 * np.log((1.0 - weighted_error) / max(weighted_error, 1e-10))\n",
    "            self.alphas.append(alpha)\n",
    "            self.models.append(model)\n",
    "\n",
    "            # Update weights\n",
    "            weights *= np.exp(-alpha * y * y_pred)\n",
    "            weights /= np.sum(weights)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros(len(x))\n",
    "        for alpha, model in zip(self.alphas, self.models):\n",
    "            pred += alpha * model.predict(x)\n",
    "        return np.sign(pred)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:43:02.469353Z",
     "start_time": "2023-12-22T00:43:02.466156Z"
    }
   },
   "id": "54300543aa3d236d"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Randomly select a subset of features\n",
    "            selected_features = np.random.choice(n_features, size=int(np.sqrt(n_features)), replace=False)\n",
    "            x_subset = x[:, selected_features]\n",
    "\n",
    "            # Create a decision tree with random features\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf\n",
    "            )\n",
    "            tree.fit(x_subset, y)\n",
    "            self.models.append((tree, selected_features))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros((x.shape[0], self.n_estimators))\n",
    "        for i, (tree, selected_features) in enumerate(self.models):\n",
    "            x_subset = x[:, selected_features]\n",
    "            pred[:, i] = tree.predict(x_subset)\n",
    "\n",
    "        # Use majority voting for the final prediction\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=pred)\n",
    "        return final_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T01:06:26.186165Z",
     "start_time": "2023-12-22T01:06:26.178330Z"
    }
   },
   "id": "f4260778e822584a"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7312059431851758\n"
     ]
    }
   ],
   "source": [
    "bagging_model = BaggingClassifier(n_estimators=100, max_depth=60)\n",
    "bagging_model.fit(xtrain, ytrain)\n",
    "\n",
    "bagging_predictions = bagging_model.predict(xtest)\n",
    "bagging_accuracy = accuracy_score(ytest, bagging_predictions)\n",
    "print(f\"Bagging Accuracy: {bagging_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:43:02.462067Z",
     "start_time": "2023-12-22T00:41:26.204446Z"
    }
   },
   "id": "789d1cdb28b22062"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7195770545776877\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(n_estimators=300)\n",
    "adaboost.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = adaboost.predict(xtest)\n",
    "\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Boosting Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T00:44:17.100901Z",
     "start_time": "2023-12-22T00:43:02.469141Z"
    }
   },
   "id": "d0b842f92c466fda"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7144696298172302\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=150, max_depth=3, min_samples_split=2, min_samples_leaf=1)\n",
    "random_forest.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = random_forest.predict(xtest)\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Random Forest Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T01:03:43.872359Z",
     "start_time": "2023-12-22T01:03:32.833333Z"
    }
   },
   "id": "571c8202d45bc0c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "We will use grid search and randomized search methods to choose better hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53df2cafbadf3fd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Random Forest model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa36548501f9040"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m rf_model \u001B[38;5;241m=\u001B[39m RandomForestClassifier()\n\u001B[1;32m     12\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mrf_model, param_grid\u001B[38;5;241m=\u001B[39mparams, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mytrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGrid search: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m best_params \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/model_selection/_search.py:898\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    892\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    893\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    894\u001B[0m     )\n\u001B[1;32m    896\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 898\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    902\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/model_selection/_search.py:1422\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1420\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1421\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1422\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/model_selection/_search.py:845\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    838\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    839\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    841\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    842\u001B[0m         )\n\u001B[1;32m    843\u001B[0m     )\n\u001B[0;32m--> 845\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    865\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    866\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    867\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     64\u001B[0m )\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/model_selection/_validation.py:729\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    727\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    728\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 729\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    731\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    732\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    733\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "Cell \u001B[0;32mIn[63], line 24\u001B[0m, in \u001B[0;36mRandomForestClassifier.fit\u001B[0;34m(self, x, y)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# Create a decision tree with random features\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     tree \u001B[38;5;241m=\u001B[39m DecisionTreeClassifier(\n\u001B[1;32m     20\u001B[0m         max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_depth,\n\u001B[1;32m     21\u001B[0m         min_samples_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_samples_split,\n\u001B[1;32m     22\u001B[0m         min_samples_leaf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_samples_leaf\n\u001B[1;32m     23\u001B[0m     )\n\u001B[0;32m---> 24\u001B[0m     \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_subset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mappend((tree, selected_features))\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/tree/_classes.py:959\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    930\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[1;32m    931\u001B[0m \n\u001B[1;32m    932\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    956\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 959\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    961\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    963\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/tree/_classes.py:443\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    433\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[1;32m    434\u001B[0m         splitter,\n\u001B[1;32m    435\u001B[0m         min_samples_split,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    440\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[1;32m    441\u001B[0m     )\n\u001B[0;32m--> 443\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 250],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Grid search: \")\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(xtest, ytest)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Test Set Score:\", test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T11:12:05.383647Z",
     "start_time": "2023-12-22T10:35:26.478072Z"
    }
   },
   "id": "9cf4faa9cf9d9238"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=params, n_iter=3, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Random Search: \")\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(xtest, ytest)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Test Set Score:\", test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T10:13:01.433806Z"
    }
   },
   "id": "f1c270c671b54462"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66a792c905095c1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
