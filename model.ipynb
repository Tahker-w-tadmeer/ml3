{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:09.542357Z",
     "end_time": "2023-12-22T17:17:11.146408Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tahkeer_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BaggingClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth  \n",
    "        self.models = [DecisionTreeClassifier(max_depth=self.max_depth) for _ in range(n_estimators)] \n",
    "        \n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        for model in self.models:\n",
    "            indices = np.random.choice(len(x), len(x), replace=True)\n",
    "            x_subset, y_subset = x.iloc[indices], y.iloc[indices] \n",
    "            model.fit(x_subset, y_subset)\n",
    "        \n",
    "        return self\n",
    "            \n",
    "\n",
    "    def predict(self, x, threshold=0.5):\n",
    "        pred = np.zeros((len(x), self.n_estimators))\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred[:, i] = model.predict(x)\n",
    "        avg_predictions = np.mean(pred, axis=1)\n",
    "        binary_predictions = (avg_predictions >= threshold).astype(int)\n",
    "        return binary_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:11.147406Z",
     "end_time": "2023-12-22T17:17:13.275701Z"
    }
   },
   "id": "9fac969431223e6e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "columns.remove(\"smoking\")\n",
    "features_x = df[columns]\n",
    "class_y = df[\"smoking\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:13.278694Z",
     "end_time": "2023-12-22T17:17:13.283178Z"
    }
   },
   "id": "fe9ab1e20fe86d44"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features_x, class_y, test_size=0.30, shuffle=False, train_size=0.70)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:13.283178Z",
     "end_time": "2023-12-22T17:17:13.306687Z"
    }
   },
   "id": "cd37abfe3e698ec6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, max_depth=4):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            model.fit(x, y, sample_weight=weights)\n",
    "            y_pred = model.predict(x)\n",
    "            weighted_error = np.sum(weights[y_pred != y])\n",
    "            if weighted_error >= 0.5:\n",
    "                break\n",
    "\n",
    "            alpha = 0.5 * np.log((1.0 - weighted_error) / max(weighted_error, 1e-10))\n",
    "            self.alphas.append(alpha)\n",
    "            self.models.append(model)\n",
    "\n",
    "            # Update weights\n",
    "            weights *= np.exp(-alpha * y * y_pred)\n",
    "            weights /= np.sum(weights)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros(len(x))\n",
    "        for alpha, model in zip(self.alphas, self.models):\n",
    "            pred += alpha * model.predict(x)\n",
    "        return np.sign(pred)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:13.310681Z",
     "end_time": "2023-12-22T17:17:13.322052Z"
    }
   },
   "id": "54300543aa3d236d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = x.shape\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Randomly select a subset of features\n",
    "            selected_features = np.random.choice(n_features, size=int(np.sqrt(n_features)), replace=False)\n",
    "            x_subset = x[:, selected_features]\n",
    "\n",
    "            # Create a decision tree with random features\n",
    "            tree = DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_samples_leaf=self.min_samples_leaf\n",
    "            )\n",
    "            tree.fit(x_subset, y)\n",
    "            self.models.append((tree, selected_features))\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        pred = np.zeros((x.shape[0], self.n_estimators))\n",
    "        for i, (tree, selected_features) in enumerate(self.models):\n",
    "            x_subset = x[:, selected_features]\n",
    "            pred[:, i] = tree.predict(x_subset)\n",
    "\n",
    "        # Use majority voting for the final prediction\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=pred)\n",
    "        return final_predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split,\n",
    "            'min_samples_leaf': self.min_samples_leaf\n",
    "        }\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            return self\n",
    "\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        \n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:13.318130Z",
     "end_time": "2023-12-22T17:17:13.327570Z"
    }
   },
   "id": "f4260778e822584a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7304250559284117\n"
     ]
    }
   ],
   "source": [
    "bagging_model = BaggingClassifier(n_estimators=100, max_depth=60)\n",
    "bagging_model.fit(xtrain, ytrain)\n",
    "\n",
    "bagging_predictions = bagging_model.predict(xtest)\n",
    "bagging_accuracy = accuracy_score(ytest, bagging_predictions)\n",
    "print(f\"Bagging Accuracy: {bagging_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:17:13.324552Z",
     "end_time": "2023-12-22T17:18:52.725646Z"
    }
   },
   "id": "789d1cdb28b22062"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Accuracy: 0.7187117470769491\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoost(n_estimators=300)\n",
    "adaboost.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = adaboost.predict(xtest)\n",
    "\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Boosting Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:18:52.727641Z",
     "end_time": "2023-12-22T17:19:45.080684Z"
    }
   },
   "id": "d0b842f92c466fda"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7114093959731543\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=150, max_depth=3, min_samples_split=2, min_samples_leaf=1)\n",
    "random_forest.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = random_forest.predict(xtest)\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "print(f'Random Forest Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-22T17:19:45.081684Z",
     "end_time": "2023-12-22T17:19:51.924367Z"
    }
   },
   "id": "571c8202d45bc0c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "We will use grid search and randomized search methods to choose better hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53df2cafbadf3fd1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def print_results(search_results):\n",
    "    best_params = search_results.best_params_\n",
    "    best_score = search_results.best_score_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Bagging model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200, 250, 300, 500, 1000],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
    "}\n",
    "\n",
    "bagging = BaggingClassifier()\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=params, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "print(\"Grid search - Bagging: \")\n",
    "print_results(grid_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=bagging, param_distributions=params, n_iter=6, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(xtrain, ytrain)\n",
    "print(\"Random search - Bagging: \")\n",
    "print_results(random_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning AdaBoost model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100}\n",
      "Best Score: 0.714262437542956\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200, 250, 300, 500, 1000],\n",
    "}\n",
    "\n",
    "adaboost = AdaBoost()\n",
    "grid_search = GridSearchCV(estimator=adaboost, param_grid=params, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "print(\"Grid search - AdaBoost: \")\n",
    "print_results(grid_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=adaboost, param_distributions=params, n_iter=6, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(xtrain, ytrain)\n",
    "print(\"Random search - AdaBoost: \")\n",
    "print_results(random_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Random Forest model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m best_score \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_score_\n\u001B[0;32m     19\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[1;32m---> 20\u001B[0m test_score \u001B[38;5;241m=\u001B[39m \u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m(xtest, ytest)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_score)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'RandomForestClassifier' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200, 250],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=params, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Grid search - Random Forest: \")\n",
    "print_results(grid_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "Best Score: 0.7218332975427687\n"
     ]
    }
   ],
   "source": [
    "print_results(grid_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search: \n",
      "Best Parameters: {'n_estimators': 1000}\n",
      "Best Score: 0.7122634546124046\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=params, n_iter=6, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Random Search - Random Forest: \")\n",
    "print_results(random_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
